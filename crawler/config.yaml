# Crawler Configuration
# ====================
# Main configuration file for the Massalia Events Crawler.
# Source websites are configured separately in config/sources.yaml

# Sources configuration file (relative to this file)
sources_file: "config/sources.yaml"

# Output directories (relative to crawler/ directory)
output_dir: "../content/events"
image_dir: "../static/images/events"

# Logging configuration
# log_level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# - DEBUG: Detailed info for debugging (URLs, selectors, data)
# - INFO: Normal operations (sources crawled, events created)
# - WARNING: Non-critical issues (missing fields, retries)
# - ERROR: Failures that skip items (parse errors, download fails)
# - CRITICAL: Fatal errors that stop execution
logging:
  log_level: "INFO"
  log_file: "logs/crawler.log"
  log_format: "text"  # "text" for human-readable, "json" for structured
  max_file_size: 10485760  # 10MB in bytes
  backup_count: 5

# HTTP settings (global defaults, can be overridden per source)
http:
  timeout: 30
  retry_count: 3
  retry_delay: 1.0
  rate_limit_delay: 1.0
  user_agent: "MassaliaEventsCrawler/1.0 (+https://massalia.events)"

# Image processing settings
image_settings:
  max_width: 1200
  quality: 85
  format: "webp"
